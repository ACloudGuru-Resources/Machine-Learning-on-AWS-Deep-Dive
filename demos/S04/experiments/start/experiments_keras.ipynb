{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9590386b-3011-41b7-ad13-9e9b0f333831",
   "metadata": {},
   "source": [
    "# Using Experiments with the MNIST Dataset and Keras\n",
    "\n",
    "## Environment Setup\n",
    "\n",
    "- Image: TensorFlow 2.6 CPU Optimized\n",
    "- Kernel: Python 3\n",
    "- Instance type: ml.t3.medium\n",
    "\n",
    "## Background\n",
    "\n",
    "This notebook uses the SageMaker SDK to demonstrate how to use experiments.  Using the MNIST dataset (a large database of handwritten digits), we use Keras to train the model.  To write log metrics back to Experiments, we use a Keras callback.\n",
    "\n",
    "This notebook has been adapted from the [SageMaker examples](https://github.com/aws/amazon-sagemaker-examples/blob/main//sagemaker-experiments/local_experiment_tracking/keras_experiment.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edfe71e-41a1-46a0-82d5-cb28ad7babca",
   "metadata": {},
   "source": [
    "## Initialize Environment and Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4441577d-2e3d-4821-aa0e-816416d90165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9b4a04-cfc1-4c51-98c3-eb264319ab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure we have the latest versions of the SDKs\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!{sys.executable} -m pip install --upgrade boto3\n",
    "!{sys.executable} -m pip install --upgrade sagemaker\n",
    "!{sys.executable} -m pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a614bd72-736e-4e11-8010-f3cc0c7218fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.session import Session\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "# Get the SageMaker and boto sessions, plus the execution role from the SageMaker domain\n",
    "sagemaker_session = Session()\n",
    "boto_sess = boto3.Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "sm = boto_sess.client(\"sagemaker\")\n",
    "region = boto_sess.region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22790f8b-efd7-44c5-abd9-95777b3503cd",
   "metadata": {},
   "source": [
    "---\n",
    "## Data\n",
    "\n",
    "For this lesson, we're using the MNIST dataset, downloading it from the SageMaker sample files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64bcfb1-d173-450e-be19-bda3fa14f097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb84df1-aac7-4b21-aac2-f6cf3982f10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422a4048-fa31-4b0a-82ef-11b87421f5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "train_path = \"datasets/input_train.npy\"\n",
    "test_path = \"datasets/input_test.npy\"\n",
    "train_labels_path = \"datasets/input_train_labels.npy\"\n",
    "test_labels_path = \"datasets/input_test_labels.npy\"\n",
    "\n",
    "# Load the data and split it between train and test sets\n",
    "s3.download_file(\"sagemaker-sample-files\", \"datasets/image/MNIST/numpy/input_train.npy\", train_path)\n",
    "s3.download_file(\"sagemaker-sample-files\", \"datasets/image/MNIST/numpy/input_test.npy\", test_path)\n",
    "s3.download_file(\n",
    "    \"sagemaker-sample-files\", \"datasets/image/MNIST/numpy/input_train_labels.npy\", train_labels_path\n",
    ")\n",
    "s3.download_file(\n",
    "    \"sagemaker-sample-files\", \"datasets/image/MNIST/numpy/input_test_labels.npy\", test_labels_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84e5137-b118-4e2d-af36-a21ae2273239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for training\n",
    "x_train = np.load(train_path)\n",
    "x_test = np.load(test_path)\n",
    "y_train = np.load(train_labels_path)\n",
    "y_test = np.load(test_labels_path)\n",
    "\n",
    "# Reshape the arrays\n",
    "x_train = np.reshape(x_train, (60000, 28, 28))\n",
    "x_test = np.reshape(x_test, (10000, 28, 28))\n",
    "y_train = np.reshape(y_train, (60000,))\n",
    "y_test = np.reshape(y_test, (10000,))\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "# Convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656cf0df-ee2a-45e8-b098-449016359db9",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4354d1-fa42-464e-b6ba-6bde912cad4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(dropout=0.5):\n",
    "    \"\"\" \"\"\"\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=input_shape),\n",
    "            layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            layers.Flatten(),\n",
    "            layers.Dropout(dropout),\n",
    "            layers.Dense(num_classes, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892b2b53-139f-45f7-84b4-9f4aa3f9efd8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define the Keras Callback\n",
    "\n",
    "The Keras Callback class provides a method *on_epoch_end*, which emits metrics at the end of each epoch. All emitted metrics will be logged in the run passed to the callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30da9d5b-2e3d-472f-b4e4-87f92e03241d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentCallback(keras.callbacks.Callback):\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    def __init__(self, run, model, x_test, y_test):\n",
    "        \"\"\"Save params in constructor\"\"\"\n",
    "        self.run = run\n",
    "        self.model = model\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \"\"\" \"\"\"\n",
    "        keys = list(logs.keys())\n",
    "        for key in keys:\n",
    "            self.run.log_metric(name=key, value=logs[key], step=epoch)\n",
    "            print(\"{} -> {}\".format(key, logs[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfcecc5-e00a-4af0-b6e3-7984e6d543ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Set up a SageMaker Experiment and its Runs, then Train\n",
    "\n",
    "Next, we train the Keras model locally on the same instance where this notebook is running.  With each run, we track the input artifacts and write them to files.  We use the ExperimentCallback method to log the metrics to the Experiment run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3471abdc-6fba-4d79-92bf-ff8b5fd98804",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.experiments.run import Run\n",
    "\n",
    "batch_size = 20\n",
    "epochs = 3\n",
    "dropout = 0.5\n",
    "\n",
    "model = get_model(dropout)\n",
    "\n",
    "experiment_name = \"mnist-keras-experiment\"\n",
    "run_name = \"mnist-keras-batch-size-20\"\n",
    "with Run(experiment_name=experiment_name, run_name=run_name, sagemaker_session=sagemaker_session) as run:\n",
    "    run.log_parameter(\"batch_size\", batch_size)\n",
    "    run.log_parameter(\"epochs\", epochs)\n",
    "    run.log_parameter(\"dropout\", dropout)\n",
    "\n",
    "    run.log_file(\"datasets/input_train.npy\", is_output=False)\n",
    "    run.log_file(\"datasets/input_test.npy\", is_output=False)\n",
    "    run.log_file(\"datasets/input_train_labels.npy\", is_output=False)\n",
    "    run.log_file(\"datasets/input_test_labels.npy\", is_output=False)\n",
    "\n",
    "    # Train locally\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[ExperimentCallback(run, model, x_test, y_test)],\n",
    "    )\n",
    "\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\", score[1])\n",
    "\n",
    "    run.log_metric(name=\"Final Test Loss\", value=score[0])\n",
    "    run.log_metric(name=\"Final Test Accuracy\", value=score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1307f6a-fcd1-4228-b18d-4e2b90383c62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete the experiment\n",
    "from sagemaker.experiments.experiment import _Experiment\n",
    "\n",
    "exp = _Experiment.load(experiment_name=experiment_name, sagemaker_session=sagemaker_session)\n",
    "exp._delete_all(action=\"--force\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abb7543-0ac6-4893-9fa5-7f61206b9819",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.6 Python 3.8 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/tensorflow-2.6-cpu-py38-ubuntu20.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
